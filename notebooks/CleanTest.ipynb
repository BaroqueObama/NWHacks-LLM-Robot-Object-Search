{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage, \n",
    "    AIMessage, \n",
    "    SystemMessage,\n",
    "    BaseMessage,\n",
    "    trim_messages\n",
    ")\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate, \n",
    "    MessagesPlaceholder,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate\n",
    ")\n",
    "\n",
    "from typing import Sequence\n",
    "\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "import base64\n",
    "from mimetypes import guess_type\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image to URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode a local image into data URL \n",
    "def local_image_to_data_url(image_path):\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    # Default to png\n",
    "    if mime_type is None:\n",
    "        mime_type = 'image/png'\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens=5,\n",
    "    strategy=\"last\",\n",
    "    token_counter=len,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    # start_on=\"human\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_prompt_template = ChatPromptTemplate.from_messages(\n",
    "#     messages=[\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"\"\"You are a robot controller. You will give instructions to a jetbot to navigate to a {object} based on an image input on what the robot sees.\n",
    "#             If there is a wall in front, turn away from the wall. \"\"\",\n",
    "#        # Roleplay setting, tell it what it is, setting, location, objective, details on the task.\n",
    "#         ),\n",
    "#         # Examples [3 examples of it spotting a dog, empty screen, 3 obstacles, Wall, Examples of continuation.]\n",
    "#         HumanMessage(content=\"These are the instructions you have given so far.\"), \n",
    "#         # Previous instructions given by the llm.\n",
    "#         MessagesPlaceholder(variable_name=\"messages\"), \n",
    "        \n",
    "#         # Prompt: Describe the image, in the context of previous instructions, reason on direction of travel. \n",
    "#         HumanMessage(content=\"\"\"Now, quickly summarize the recent instructions you have given so far. Describe the following image. \n",
    "#                      If there is a {object} describe which direction the robot should travel to approach the {object}. \n",
    "#                      Else, specify a direction the robot should move to find a new {object}. Strictly write your response in this format:\n",
    "#                      '<reasoning>.[<command><value>]', where reasoning is the rationale behind the chosen move. Available commands are t for turn value (int) in degrees\n",
    "#                      positive for left and negative for right. And f for forward value (int) seconds\"\"\"),\n",
    "#         HumanMessagePromptTemplate.from_template(\n",
    "#             [{'image_url': {'url': '{image_path}', 'detail': '{detail_parameter}'}}]\n",
    "#         )\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def message_to_string(trimmings):\n",
    "    n = 1\n",
    "    result = \"\"\n",
    "    for message in trimmings:\n",
    "        result += \"\\n\" + f\"Instruction Number {n}:\" + message.content\n",
    "        n += 1\n",
    "    result += \"End of Instructioins you have given so far.\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    detail_parameter: str\n",
    "    image_path: str\n",
    "    \n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "    prompt = image_prompt_template.invoke(\n",
    "        {\"messages\": message_to_string(trimmed_messages), \"detail_parameter\": state[\"detail_parameter\"], \"image_path\": state[\"image_path\"]}\n",
    "    )\n",
    "    print(prompt)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc456\"}}\n",
    "object = \"dog\"\n",
    "detail_parameter = 'high'\n",
    "path = \"images/imageofdog.png\"\n",
    "# url = local_image_to_data_url(path)\n",
    "url = \"https://thumbs.dreamstime.com/b/empty-grass-field-24508096.jpg\"\n",
    "\n",
    "output = app.invoke(\n",
    "    {\"object\": object, \"detail_parameter\": detail_parameter, \"image_path\": url},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object = \"dog\"\n",
    "# detail_parameter = 'high'\n",
    "path = \"images/corner.png\"\n",
    "# url = local_image_to_data_url(path)\n",
    "url = \"https://hips.hearstapps.com/hmg-prod/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg?crop=0.752xw:1.00xh;0.175xw,0&resize=1200:*\"\n",
    "output = app.invoke(\n",
    "    {\"object\": object, \"detail_parameter\": detail_parameter, \"image_path\": url},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = app.get_state(config).values\n",
    "\n",
    "for message in state[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRG8 to PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def brg8_to_png(brg8_data, width, height, output_path):\n",
    "    \"\"\"\n",
    "    Converts BRG8 data to PNG format and saves it.\n",
    "    \n",
    "    :param brg8_data: A flat byte array or numpy array with BRG8 data.\n",
    "    :param width: Width of the image.\n",
    "    :param height: Height of the image.\n",
    "    :param output_path: Path to save the PNG file.\n",
    "    \"\"\"\n",
    "    # Ensure the input data is a numpy array\n",
    "    if not isinstance(brg8_data, np.ndarray):\n",
    "        brg8_data = np.array(brg8_data, dtype=np.uint8)\n",
    "\n",
    "    # Reshape the data into (height, width, 3) format\n",
    "    brg_image = brg8_data.reshape((height, width, 3))\n",
    "\n",
    "    # Convert BRG to RGB by rearranging the channels\n",
    "    rgb_image = brg_image[:, :, [1, 2, 0]]  # [Red, Green, Blue]\n",
    "\n",
    "    # Create a Pillow Image from the RGB data\n",
    "    img = Image.fromarray(rgb_image, 'RGB')\n",
    "\n",
    "    # Save as PNG\n",
    "    img.save(output_path)\n",
    "    print(f\"Image saved to {output_path}\")\n",
    "\n",
    "# Example Usage:\n",
    "# Simulated BRG8 data (flat array)\n",
    "width, height = 640, 480  # Image dimensions\n",
    "brg8_data = np.random.randint(0, 256, size=(height * width * 3), dtype=np.uint8)\n",
    "\n",
    "# Convert and save to PNG\n",
    "brg8_to_png(brg8_data, width, height, \"output.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Brainrot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
