{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage, \n",
    "    AIMessage, \n",
    "    SystemMessage,\n",
    "    BaseMessage,\n",
    "    trim_messages\n",
    ")\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate, \n",
    "    MessagesPlaceholder,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate\n",
    ")\n",
    "\n",
    "from typing import Sequence\n",
    "\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "import base64\n",
    "from mimetypes import guess_type\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode a local image into data URL \n",
    "def local_image_to_data_url(image_path):\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    # Default to png\n",
    "    if mime_type is None:\n",
    "        mime_type = 'image/png'\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens=5,\n",
    "    strategy=\"last\",\n",
    "    token_counter=len,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    # start_on=\"human\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "\n",
    "# Example Scenarios with Continuous Thought (Variable Length and Edge Cases)\n",
    "examples = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            \"The JetBot was facing a wall. [t30]\",\n",
    "            \"The JetBot turned left again to clear the same wall. [t30]\",\n",
    "            \"The JetBot moved forward to explore the area. [f3]\",\n",
    "            \"The JetBot encountered a small rock and turned slightly to the right. [t-15]\"\n",
    "        ],\n",
    "        \"image_input\": \"The dog is slightly visible through the smoke on the left.\",\n",
    "        \"expected_response\": \"The dog is slightly visible through the smoke on the left, so the JetBot will turn left to align with it. [t30]\"\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            \"The JetBot is in a corner and turned right to avoid it. [t-45]\",\n",
    "            \"The JetBot moved forward for 5 seconds to explore further. [f5]\",\n",
    "            \"The JetBot detected a low-hanging obstacle and turned left. [t30]\",\n",
    "            \"The JetBot turned slightly right to readjust its path. [t-15]\",\n",
    "            \"The JetBot encountered a thick patch of smoke and paused to reassess. [f0.5]\"\n",
    "        ],\n",
    "        \"image_input\": \"No objects detected, but a clearing is visible ahead.\",\n",
    "        \"expected_response\": \"No objects detected, but a clearing is visible ahead, so the JetBot will move forward cautiously. [f3]\"\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            \"The JetBot detected an object directly ahead and approached it. [f4]\",\n",
    "            \"The JetBot encountered a wall and turned right. [t-90]\",\n",
    "            \"The JetBot moved forward to reposition. [f2]\",\n",
    "            \"The JetBot detected a path leading left and turned to follow it. [t30]\",\n",
    "            \"The JetBot adjusted slightly to center itself in the path. [t-10]\",\n",
    "            \"The JetBot paused briefly to analyze the smoky environment. [f0.5]\"\n",
    "        ],\n",
    "        \"image_input\": \"An object is directly in front, slightly obscured by smoke.\",\n",
    "        \"expected_response\": \"The object is directly in front, slightly obscured by smoke, so the JetBot will move forward to approach it. [f3.5]\"\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            \"The JetBot moved forward into the smoke to explore. [f4]\",\n",
    "            \"The JetBot encountered a wall and turned sharply left. [t90]\",\n",
    "            \"The JetBot adjusted to the right to avoid an unseen obstacle. [t-20]\",\n",
    "            \"The JetBot moved forward cautiously. [f2]\",\n",
    "            \"The JetBot turned left to realign after hitting another corner. [t30]\",\n",
    "            \"The JetBot detected an opening and moved forward. [f3.5]\",\n",
    "            \"The JetBot detected the object on the right and began to approach. [t-30]\"\n",
    "        ],\n",
    "        \"image_input\": \"The object is now directly ahead in a clearing.\",\n",
    "        \"expected_response\": \"The object is now directly ahead in a clearing, so the JetBot will move forward to reach it. [f5]\"\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            \"The JetBot was facing a wall and turned left slightly. [t15]\",\n",
    "            \"The JetBot was still slightly facing the wall and turned left again to clear it. [t15]\",\n",
    "            \"The JetBot moved forward to ensure it avoided the wall entirely. [f3]\",\n",
    "            \"The JetBot encountered another corner and turned sharply left. [t90]\",\n",
    "            \"The JetBot moved forward through the smoke. [f4]\",\n",
    "            \"The JetBot detected an object directly in front. [f3]\"\n",
    "        ],\n",
    "        \"image_input\": \"The object is slightly to the left of the screen.\",\n",
    "        \"expected_response\": \"The object is slightly to the left of the screen, so the JetBot will turn left to align with it. [t30]\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_text = \"\\n\".join(\n",
    "    f\"Example {i+1}:\\n\"\n",
    "    f\"Past Messages:\\n\" + \"\\n\".join(f\"  {msg}\" for msg in example[\"messages\"]) +\n",
    "    f\"\\nImage Input:\\n  {example['image_input']}\\nExpected Response:\\n  {example['expected_response']}\\n\"\n",
    "    for i, example in enumerate(examples)\n",
    ")\n",
    "\n",
    "\n",
    "image_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "        (\n",
    "            \"system\",\n",
    "            f\"\"\"You are a robot controller tasked with navigating a JetBot to a dog. \n",
    "            The JetBot receives image inputs and must reason about its environment and past actions to choose the best path forward. \n",
    "            The JetBot operates inside a tent and in a smoky environment, which may obscure visibility. \n",
    "            If the JetBot encounters obstacles (e.g., walls, corners, or other objects), turn to avoid them. \n",
    "            Always reason step-by-step and base your decisions on continuity from past actions.\n",
    "            \n",
    "            Here are examples of how you should reason and respond:\n",
    "            {example_text}\n",
    "            \"\"\"\n",
    "        ),\n",
    "        # MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"\"\"Now here are the actual instructions and reasoning you have given the Jetbot so far: {messages}\n",
    "            First, summarize the instructions you have given so far sequentially. (Start with Instruction 1, If there are none, don't.). \n",
    "            Secondly, describe the following image. (If there is a dog, describe its location and determine the direction the JetBot should travel to approach the dog. \n",
    "            If no dog is detected, analyze the environment and choose a direction to continue exploring.)\n",
    "            Finally, use prior instructions and outcomes to reason about the next move. Strictly format your response as:\n",
    "            '<reasoning>. [<command><value>]'\"\"\"\n",
    "        ),\n",
    "        # MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        # HumanMessagePromptTemplate.from_template(\n",
    "        #     \"Here is the image input: {image_url}\"\n",
    "        # ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            [{'image_url': {'url': '{image_path}', 'detail': '{detail_parameter}'}}]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# The prompt template now includes extended examples, reasoning continuity, and adherence to strict formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def message_to_string(trimmings):\n",
    "    n = 1\n",
    "    result = \"\"\n",
    "    for message in trimmings:\n",
    "        result += \"\\n\" + f\"Instruction Number {n}:\" + message.content\n",
    "        n += 1\n",
    "    result += \"End of Instructioins you have given so far.\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    detail_parameter: str\n",
    "    image_path: str\n",
    "    \n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "    prompt = image_prompt_template.invoke(\n",
    "        {\"messages\": message_to_string(trimmed_messages), \"detail_parameter\": state[\"detail_parameter\"], \"image_path\": state[\"image_path\"]}\n",
    "    )\n",
    "    print(prompt)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jetbot Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)  # this width and height doesn't necessarily have to match the camera\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from uuid import uuid1\n",
    "\n",
    "free_dir = 'images'\n",
    "\n",
    "try:\n",
    "    os.makedirs(free_dir)\n",
    "except FileExistsError:\n",
    "    print('Directories not created because they already exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_snapshot(directory):\n",
    "    # image_path = os.path.join(directory, str(uuid1()) + '.png')\n",
    "    image_path = os.path.join(directory, 'view.png')\n",
    "\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(image.value)\n",
    "        \n",
    "def save_free():\n",
    "    global free_dir\n",
    "    save_snapshot(free_dir)\n",
    "    \n",
    "def turn(args):\n",
    "    try:\n",
    "        angle = int(args)\n",
    "        duration = abs(angle) / 90\n",
    "        if angle > 0:\n",
    "            robot.left(0.11)\n",
    "        else:\n",
    "            robot.right(0.11)\n",
    "        time.sleep(duration)\n",
    "        robot.stop()\n",
    "        time.sleep(0.1)\n",
    "        return f\"Turned {angle} degrees.\"\n",
    "    except ValueError:\n",
    "        return \"Invalid argument for turn. Please provide an integer.\"\n",
    "\n",
    "def move_forward(args):\n",
    "    try:\n",
    "        duration = float(args)\n",
    "        robot.forward(0.15)\n",
    "        time.sleep(duration)\n",
    "        robot.stop()\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        return f\"Moved forward for {duration} seconds.\"\n",
    "    except ValueError:\n",
    "        return \"Invalid argument for move_forward. Please provide a number.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_chatbot_response(response):\n",
    "    \"\"\"Parse chatbot response for reasoning and command.\"\"\"\n",
    "    match = re.search(r\"(.+?)\\[(f|t)([-\\d.]+)]\", response)\n",
    "    reasoning = match.group(1).strip() if match else \"No reasoning provided.\"\n",
    "    command = match.group(2) if match else None\n",
    "    value = match.group(3) if match else None\n",
    "    return reasoning, command, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc456\"}}\n",
    "detail_parameter = 'high'\n",
    "path = \"images/imageofdog.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (True):\n",
    "    save_free()\n",
    "\n",
    "    url = local_image_to_data_url(path)\n",
    "\n",
    "    output = app.invoke(\n",
    "        {\"detail_parameter\": detail_parameter, \"image_path\": url},\n",
    "        config,\n",
    "    )\n",
    "    \n",
    "    reasoning, command, value = parse_chatbot_response(output.messages[-1].content)\n",
    "    if command == \"f\":\n",
    "        move_forward(value)\n",
    "    elif command == \"t\":\n",
    "        turn(value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Brainrot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
